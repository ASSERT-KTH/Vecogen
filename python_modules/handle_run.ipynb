{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling of results from a single run of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_folder: anthropic/claude-sonnet-4-10-10-1-one-shot-both\n",
      "python3 main.py generate_code_folder -d ../journal_problems/ -samples 10 -iter 10 -temp 1 -wpt 10 -o ../output/anthropic/claude-sonnet-4-10-10-1-one-shot-both -of generated_code.c -fsf formal_specification.h -nl natural_language_specification.h -sig function_signature.c -pt one-shot -spectype both -model anthropic/claude-sonnet-4 -tc solution_test.c -extra extras.c -wpm real\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "\n",
    "# Settings\n",
    "# model = \"gp\"\n",
    "model = \"anthropic/claude-sonnet-4\"\n",
    "temperature = 1\n",
    "samples_generated = 10\n",
    "feedback_iterations = 10\n",
    "one_shot = True\n",
    "spec_type = \"both\"  # [\"natural\", \"formal\", \"both\"]\n",
    "\n",
    "# Inputs\n",
    "formal_specification_name = \"formal_specification.h\"\n",
    "natural_language_specification_name = \"natural_language_specification.h\"\n",
    "function_signature_name = \"function_signature.c\"\n",
    "extra_code_name = \"extras.c\"\n",
    "test_cases_name = \"solution_test.c\"\n",
    "\n",
    "prompt_type = \"one-shot\" if one_shot else \"zero-shot\"\n",
    "output_folder_name = f\"{model}-{samples_generated}-{feedback_iterations}-{temperature}-{prompt_type}-{spec_type}\"\n",
    "\n",
    "problems_directory = \"../journal_problems/\"\n",
    "wp_model = \"real\"\n",
    "cmd = [\n",
    "    \"python3\", \"main.py\", \"generate_code_folder\",\n",
    "    \"-d\", \"../journal_problems/\",\n",
    "    \"-samples\", str(samples_generated),\n",
    "    \"-iter\", str(feedback_iterations),\n",
    "    \"-temp\", str(temperature),\n",
    "    \"-wpt\", \"10\",\n",
    "    \"-o\", f\"../output/{output_folder_name}\",\n",
    "    \"-of\", \"generated_code.c\",\n",
    "    \"-fsf\", formal_specification_name,          \n",
    "    \"-nl\", natural_language_specification_name, \n",
    "    \"-sig\", function_signature_name,            \n",
    "    \"-pt\", prompt_type,                         \n",
    "    \"-spectype\", spec_type,                     \n",
    "    \"-model\", model,                            \n",
    "    \"-tc\", test_cases_name,                     \n",
    "]\n",
    "\n",
    "if extra_code_name and extra_code_name.strip():\n",
    "    cmd += [\"-extra\", extra_code_name]\n",
    "\n",
    "if wp_model:\n",
    "    cmd += [\"-wpm\", wp_model]\n",
    "\n",
    "command = \" \".join(shlex.quote(x) for x in cmd)\n",
    "\n",
    "print(f\"output_folder: {output_folder_name}\")\n",
    "print(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all folders in the directory sorted by name\n",
    "folders = os.listdir(f'../output/{output_folder_name}')\n",
    "\n",
    "# Sort on number\n",
    "folders.sort(key=lambda x: int(x.split('-')[0]))\n",
    "\n",
    "# Create an empty dataframe that will be filled with info of the iterations\n",
    "iteration_array = []\n",
    "\n",
    "# Filter the folders if need be, only take ones higher than 300\n",
    "# folders = [folder for folder in folders if int(folder.split('-')[0]) >= 427]\n",
    "\n",
    "total_completions_used = []\n",
    "total_tokens_used = []\n",
    "total_completions = []\n",
    "verification_time = []\n",
    "\n",
    "# For each folder read the output and add it to the dataframe\n",
    "for folder_name in folders:\n",
    "    # Read the output given in the file \n",
    "    with open(f\"../output/{output_folder_name}/{folder_name}/results.txt\", 'r') as file:\n",
    "        # Read the file which contains an array\n",
    "        data = json.load(file)\n",
    "\n",
    "    verified_goals = []\n",
    "    passed_tests = []\n",
    "    verified_goals_percentage = []\n",
    "    passed_tests_percentage = []\n",
    "    generated_code_length = []\n",
    "    \n",
    "    total_completions_used.append(data['total_completions_used'])\n",
    "    total_tokens_used.append(data['total_tokens_used'])\n",
    "    total_completions.append(data['total_completions_requested'])\n",
    "    verification_time.append(data['total_time_taken_verification'])\n",
    "    \n",
    "    # Get all completions in the initial code generation and in each code improvement iteration\n",
    "    completions = []\n",
    "    for i in data[\"initial_code_generation_information\"][0]['completions']:\n",
    "        completions.append(i)\n",
    "    \n",
    "    for i in data[\"code_improvement_information\"]:\n",
    "        for j in i['completions']:\n",
    "            completions.append(j)\n",
    "\n",
    "    # for each iteration in the array add it to the dataframe\n",
    "    for i in completions:\n",
    "        verified_goals.append(i['verified_goals_count'])\n",
    "\n",
    "        # If the goals is 0 / 0 the percentage is 0\n",
    "        if (i['verified_goals_count'] == \"0 / 0\"):\n",
    "            verified_goals_percentage.append(0)\n",
    "        else:\n",
    "            verified_goals_percentage.append(eval(i['verified_goals_count']))\n",
    "        # If there is a compilation error the length is only 1\n",
    "        if (len(i[\"test_information\"]) == 1):\n",
    "            passed_tests.append(f\"{i['test_information']['summary']['passed']} / {i['test_information']['summary']['total']}\")\n",
    "            passed_tests_percentage.append(0)\n",
    "        else:\n",
    "            passed_tests.append(f\"{i['test_information'][-1]['summary']['passed']} / {i['test_information'][-1]['summary']['total']}\")\n",
    "            passed_tests_percentage.append(i['test_information'][-1]['summary']['passed'] / i['test_information'][-1]['summary']['total'])\n",
    "\n",
    "        # Get the length of the generated code at this iteration by counting the newlines\n",
    "        generated_code_length.append(i['gpt_output'].count(\"\\n\"))\n",
    "\n",
    "    # Add it as a column to the dataframe\n",
    "    iteration_array.append(verified_goals)\n",
    "    iteration_array.append(passed_tests)\n",
    "    iteration_array.append(verified_goals_percentage)\n",
    "    iteration_array.append(passed_tests_percentage)\n",
    "    iteration_array.append(generated_code_length)\n",
    "\n",
    "# Create a dataframe with the information of the iterations\n",
    "df = pd.DataFrame(iteration_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work together with google sheets and google drive to store the information and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSEGEZ\\AppData\\Local\\Temp\\ipykernel_39212\\1976603367.py:34: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet.update(start_cell, data_to_update)\n",
      "C:\\Users\\MSEGEZ\\AppData\\Local\\Temp\\ipykernel_39212\\1976603367.py:52: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet.update(\"L50:O424\", total_extra_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1fTotOpVTfxCr84Wg2inBKAn-ELfgLQMkM8qnmRT_UQE',\n",
       " 'updatedRange': \"'anthropic/claude-sonnet-4-10-10-1-one-shot-both'!L50:O374\",\n",
       " 'updatedRows': 325,\n",
       " 'updatedColumns': 4,\n",
       " 'updatedCells': 1300}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# ---- auth ----\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "    \"../tmp/vecogen-3f08ff3c7219.json\", SCOPES\n",
    ")\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# ---- spreadsheet + template ----\n",
    "SPREADSHEET_ID = \"1fTotOpVTfxCr84Wg2inBKAn-ELfgLQMkM8qnmRT_UQE\"\n",
    "sheet = client.open_by_key(SPREADSHEET_ID)\n",
    "\n",
    "template_sheet_descriptive_name = \"result_template\"\n",
    "template_ws = sheet.worksheet(template_sheet_descriptive_name)\n",
    "\n",
    "# ---- duplicate template as last sheet with new name ----\n",
    "new_sheet_name = output_folder_name  # assume defined\n",
    "sheet.duplicate_sheet(\n",
    "    source_sheet_id=template_ws.id,\n",
    "    insert_sheet_index=len(sheet.worksheets()),  # last position\n",
    "    new_sheet_name=new_sheet_name,\n",
    ")\n",
    "\n",
    "worksheet = sheet.worksheet(new_sheet_name)\n",
    "\n",
    "# ---- write the main table starting at R50 (auto-sizes to df) ----\n",
    "start_cell = \"R50\"\n",
    "data_to_update = df.values.tolist()\n",
    "worksheet.update(start_cell, data_to_update)\n",
    "\n",
    "# ---- write single cells ----\n",
    "worksheet.update_acell(\"C3\",  model)\n",
    "worksheet.update_acell(\"C4\",  temperature)\n",
    "worksheet.update_acell(\"C5\",  samples_generated)\n",
    "worksheet.update_acell(\"C6\",  feedback_iterations)\n",
    "worksheet.update_acell(\"C7\",  spec_type)\n",
    "worksheet.update_acell(\"C8\",  command)\n",
    "worksheet.update_acell(\"C9\",  sum(verification_time))\n",
    "worksheet.update_acell(\"C11\", prompt_type)\n",
    "\n",
    "# ---- write the extra block ----\n",
    "total_extra_data = []\n",
    "for i in range(len(total_tokens_used)):\n",
    "    total_extra_data.append([total_tokens_used[i], total_completions_used[i], total_completions[i], verification_time[i]])\n",
    "    total_extra_data += [[\"\", \"\", \"\", \"\"]] * 4\n",
    "\n",
    "worksheet.update(\"L50:O424\", total_extra_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the data in the google drive folder    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_tokens_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../output/gpt-5-10-10-1-one-shot-both uploaded to Google Drive folder with ID 1ZvsBlLV94f1TTG-2aIfeX_v86I4bOxq8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1fTotOpVTfxCr84Wg2inBKAn-ELfgLQMkM8qnmRT_UQE',\n",
       " 'updatedRange': \"'gpt-4o-1-10-0-one-shot-both'!C10\",\n",
       " 'updatedRows': 1,\n",
       " 'updatedColumns': 1,\n",
       " 'updatedCells': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the scope and authenticate using service account credentials\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "creds = Credentials.from_service_account_file('../tmp/vecogen-3f08ff3c7219.json', scopes=SCOPES)\n",
    "\n",
    "# Authenticate Google Drive API client\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "def create_folder(name, parent_id=None):\n",
    "    \"\"\"Create a folder in Google Drive.\"\"\"\n",
    "    folder_metadata = {\n",
    "        'name': name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder'\n",
    "    }\n",
    "    if parent_id:\n",
    "        folder_metadata['parents'] = [parent_id]\n",
    "    folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
    "    return folder.get('id')\n",
    "\n",
    "def upload_file(file_path, parent_id):\n",
    "    \"\"\"Upload a file to Google Drive.\"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    media = MediaFileUpload(file_path, resumable=True)\n",
    "    file_metadata = {\n",
    "        'name': file_name,\n",
    "        'parents': [parent_id]\n",
    "    }\n",
    "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    return file.get('id')\n",
    "\n",
    "def upload_folder(local_folder_path, parent_id=None):\n",
    "    \"\"\"Upload a folder to Google Drive, recursively including all files and subfolders.\"\"\"\n",
    "    folder_name = os.path.basename(local_folder_path)\n",
    "    folder_id = create_folder(folder_name, parent_id)\n",
    "    for item in os.listdir(local_folder_path):\n",
    "        item_path = os.path.join(local_folder_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            upload_folder(item_path, folder_id)\n",
    "        else:\n",
    "            upload_file(item_path, folder_id)\n",
    "\n",
    "def list_folders():\n",
    "    \"\"\"List all folders in Google Drive.\"\"\"\n",
    "    query = \"mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "    results = drive_service.files().list(q=query, spaces='drive', fields='nextPageToken, files(id, name)').execute()\n",
    "    folders = results.get('files', [])\n",
    "\n",
    "    if not folders:\n",
    "        print('No folders found.')\n",
    "    else:\n",
    "        print('Folders:')\n",
    "        for folder in folders:\n",
    "            print(f\"Name: {folder['name']}, ID: {folder['id']}\")\n",
    "\n",
    "# Define the local folder you want to upload and the Google Drive parent folder ID\n",
    "local_folder_path = f'../output/{output_folder_name}'\n",
    "drive_parent_folder_id = '1ZvsBlLV94f1TTG-2aIfeX_v86I4bOxq8'\n",
    "\n",
    "# Start the folder upload process\n",
    "upload_folder(local_folder_path, drive_parent_folder_id)\n",
    "\n",
    "print(f'Folder {local_folder_path} uploaded to Google Drive folder with ID {drive_parent_folder_id}')\n",
    "\n",
    "# Put the link in C10\n",
    "worksheet.update_acell('C10', f\"https://drive.google.com/drive/folders/{drive_parent_folder_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
